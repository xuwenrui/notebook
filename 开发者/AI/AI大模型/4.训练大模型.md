步骤：
##### 1.无监督预训练
![[Pasted image 20240623122606.png|500]]
使用海量文本训练。gtp3是3000亿个token（token是大语言模型的基本单位）。
训练：根据学习数据更新下个词的权重。 学习的数据越优质越多，预测越好
![[Pasted image 20240623122857.png|500]]

##### 2.对基座模型微调
SFT:监督微调，基座模型训练完成后得到一个SFT模型

![[Pasted image 20240623122644.png|500]]
![[Pasted image 20240623123417.png|500]]

##### 让SFT模型强化学习


![[Pasted image 20240623122715.png|500]]

![[Pasted image 20240623122746.png|500]]

###### 奖励
3H原则
使用奖励模型
![[Pasted image 20240623123705.png|500]]

##### 奖励模型
![[Pasted image 20240623123852.png|500]]

![[Pasted image 20240623123919.png|500]]

##### 强化学习
![[Pasted image 20240623123956.png|500]]
