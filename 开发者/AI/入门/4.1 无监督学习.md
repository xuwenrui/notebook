无监督学习（Unsupervised Learning）是机器学习的重要分支，其核心特点是：**训练数据没有人工标注的标签（labels）**，模型需自主发现数据中的隐藏结构、模式或规律
### 与监督学习对比

| 特性       | 监督学习             | 无监督学习           |     |
| -------- | ---------------- | --------------- | --- |
| **数据**   | `(x, y)`，含标签 `y` | 仅 `x`，无标签       |     |
| **目标**   | 预测标签 `y`         | 探索数据内在结构        |     |
| **典型任务** | 分类、回归            | 聚类、降维、异常检测、生成模型 |     |
### 核心任务与常用算法

#### 1. **聚类（Clustering）**

> 将相似样本分组，同一组内样本相似度高，组间差异大。

- **K-Means**：基于距离的聚类（需预设簇数 K）
- **层次聚类（Hierarchical）**：构建树状聚类结构
- **DBSCAN**：基于密度的聚类（可发现任意形状簇，自动处理噪声）
- **高斯混合模型（GMM）**：概率模型，假设数据服从混合高斯分布
- **MeanShift（均值漂移）聚类**是一种强大且**无需预设簇数量**的非参数聚类算法，特别适合发现**任意形状**的簇，并能自动估计簇中心。- **“爬山”策略**：每个数据点像“登山者”，沿着密度梯度（即局部均值方向）不断向高密度区域移动，直到收敛到局部密度峰值（即簇中心）。 **核密度估计（KDE）**：通过滑动窗口（核函数）估计数据密度，漂移方向指向窗口内样本的**加权均值**。

#### 2. **降维（Dimensionality Reduction）**

> 将高维数据压缩到低维，保留关键信息，便于可视化或去噪。

- **PCA（主成分分析）**：线性降维，最大化方差
- **t-SNE**：非线性降维，擅长可视化（保留局部结构）
- **UMAP**：比 t-SNE 更快，兼顾局部与全局结构
- **自编码器（Autoencoder）**：神经网络实现的非线性降维

#### 3. **异常检测（Anomaly Detection）**

> 识别与大多数数据显著不同的离群点。

- **孤立森林（Isolation Forest）**：通过随机分割路径长度检测异常
- **一类 SVM（One-Class SVM）**：学习正常数据的边界
- **基于聚类/密度的方法**：如 DBSCAN 中的噪声点

#### 4. **关联规则学习（Association Rule Learning）**

> 发现变量间的有趣关系（如购物篮分析）。

- **Apriori 算法**：挖掘频繁项集与关联规则（如 “啤酒 → 尿布”）

#### 5. **生成模型（Generative Models）**

> 学习数据分布，生成新样本。

- **GAN（生成对抗网络）**：生成器 vs 判别器对抗训练
- **VAE（变分自编码器）**：概率生成模型，学习隐空间分布
- **自回归模型**：如 PixelRNN、WaveNet

---

### 🌐 典型应用场景

| 领域        | 应用示例                 |
| --------- | -------------------- |
| **客户分群**  | 电商用户行为聚类（高价值/流失风险用户） |
| **图像处理**  | 无标签图像聚类、图像压缩（PCA）    |
| **生物信息学** | 基因表达数据分组、蛋白质结构分析     |
| **网络安全**  | 网络入侵检测（异常流量识别）       |
| **推荐系统**  | 协同过滤（基于用户/物品相似度）     |